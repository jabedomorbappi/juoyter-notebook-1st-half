{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x,n_h,n_y):\n",
    "    w1=np.random.randn(n_h,n_x)*0.01\n",
    "    b1=np.zeros((n_h,1))\n",
    "    w2=np.random.randn(n_y.n_h)*0.01\n",
    "    \n",
    "    parameters={\"w1\":w1,\n",
    "              \"b1\":b1,\n",
    "              \"w2\":w2,\n",
    "              \"b2\":b2}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_initialize_parameters(layer_dims):\n",
    "    parameters={}\n",
    "    L=len(layer_dims)\n",
    "    for i in range(1,L):\n",
    "        parameters['w'+str(i)]=np.random.randn(layer_dims[i],layer_dims[i-1])*0.01\n",
    "        parameters['b'+str(i)]=np.zeros(layer_dims[i],1)\n",
    "        \n",
    "                   \n",
    "    return parameters                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liniar_forward(A,w,b):\n",
    "    z=np.dot(w,x)+b\n",
    "    cache=(A,w,b)\n",
    "    \n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \n",
    "    A=1/1+np.exp(-z)\n",
    "    cache=z\n",
    "    return A,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    A=np.max(0,z)\n",
    "    cache=z\n",
    "    return A,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev,w,b,activation):\n",
    "    if activation=='sigmoid':\n",
    "        z,linear_cache=linear_forward(A_prev,w,b)\n",
    "        A,activation_cache=sigmoid(z)\n",
    "    elif activation=='relu':\n",
    "        z,linear_cache=linear_forward(A_prev,w,b)\n",
    "        A,activation_cache=relu(z)\n",
    "     \n",
    "    \n",
    "    cache=(linear_cache,activation_cache)\n",
    "    \n",
    "    return A,cache\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_forward(X,parameters):\n",
    "    caches=[]\n",
    "    A=X\n",
    "    L=len(parameters)//2\n",
    "    for i in range(1,L):\n",
    "        A_prev=A\n",
    "        w=parameters['w'+str(i)]\n",
    "        b=parameters['b'+str(i)]\n",
    "        A,cache=linear_activation_forward(A_prev,w,b,activation='relu')\n",
    "        caches.append(cache)\n",
    "    w=parameters['w'+str(L)]\n",
    "    b=parameters['w'+str(L)]\n",
    "    \n",
    "    AL,cache=linear_activation-forward(A_prev,w,b,activation='sigmoid')\n",
    "    caches.append(cache)\n",
    "    return AL,caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL,Y):\n",
    "    m=Y.shape[1]\n",
    "    cost=-1./m*np.sum(Y*np.log(AL)+(1-Y)*np.log(1-AL))\n",
    "    cost=np.squeeze(cost)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dz,cache):\n",
    "    A_prev,w,b=cache\n",
    "    m=A_prev.shape[1]\n",
    "    \n",
    "    dw=1./m*np.dot(dz,A_prev.T)\n",
    "    db=1./m*np.sum(dz,axis=1,keepdims=Ture)\n",
    "    dA_prev=np.dot(w.T,dz)\n",
    "    \n",
    "    \n",
    "    return dA_prev,dw,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_back(dA,cache):\n",
    "    z=cache\n",
    "    s=1/(1+np.ex(-z))\n",
    "    dz=dA*s*(1-s)\n",
    "    return dz\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_back(dA,cache):\n",
    "    z=cache\n",
    "    dz=np.array(dA,copy=True)\n",
    "    dz[z<=0]=0\n",
    "    return dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA,cache,activaion):\n",
    "    linear_cache,activation_cache=cache\n",
    "    if activation=='relu':\n",
    "        dz=relu_back(dA,activation_cache)\n",
    "        dA_prev,dw,db,linear_back_ward(dz,linear_cache)\n",
    "    elif activation=='sigmoid':\n",
    "        dz=sigmoid_back(dA,activation_cache)\n",
    "        dA_prev,dw,db=linear_backward(dz,linear_cache)\n",
    "        \n",
    "        \n",
    "    return dA_prev,dw,db     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
